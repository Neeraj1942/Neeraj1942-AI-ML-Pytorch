Images ->
They are stored in matrix of pixel values
0 represents black(lower intensity) , 255 represents white(higher intensity)
matrix of numbers is known as a channel
size of the image is length and breadth of the matrix 
pixel value tells us the intensity of the pixel

Every coloured image has 3 channels ( red green and blue) 
1. colour image -> N * M * 3 -> L * W * 3(represents number of channels) mostly RGB(red,blue,green format)
2. greyscale images -> N * M *! (1 is the channel)

3. RGBA -> Red Green Blue - Alpha
Alpha -> Denotes the transperancy
Range of Alpha - 0 to 255 -> 0: completely blurred, 255 : zero blur

3. MRI (Magnetic Resonance Imaging) -> Hight, Width, Slices, Channel 
(4D matrix), each slice represents the internal structure of the object, which gives the 4d shape.
Popular examples - > MRI images, CT scans

Greyscale -> 2-D matrix -> N * M
RGB       -> 3-D matrix -> N * M * Channel -> Channel = 3
RGBA      -> 3-D matrix -> N * M * Channel -> Channel = 4
MRI       -> 4-D matrix -> N * M *  Slices * Channel

red_filter = [1,0,0]
imshow(image * red_filter) ->
Result: you get the original red intensity of the image, displayed in red tones (not grayscale).


imshow(image[:,:,0], cmap='Reds') ->  "make a grayscale red-tinted picture based only on red brightness values."
shows the red channel as a 2D heatmap, not an RGB image.
brighter red = stronger intensity, darker = weaker.

# importing modules from skimage to read and display images
import skimage
from skimage.io import imshow, imread, imsave
from skimage.transform import resize
import numpy as np

(important imports from skimage)

1. Grayscale ->
image_gray = imread('')
image_gray.shape -> gives the shape 
image_gray -> gives the matrix of the full image

2. RGB ->

red_filter = [1,0,0]    
imshow(image*red_filter)
Can be done for blue(0,0,1) and greeen (0,1,0)

Another way to get it on a grayscale is ->
# individual channel using cmap
imshow(image[:,:,0], cmap='Reds') -> Blues, Greens, Greys and etc...

to show the matrix of :
red  -> image[:,:,0]
blue -> image[:,:,2]
green-> image[:,:,1]

RGBA ->
# print the alpha value
image_rgba[:,:,3]

#change value of alpha channel
image_rgba[:,:,3] = image_rgba[:,:,3]-100

MRI -> ( hdr -> high dynamic range)
# loading library to read images ( important library for MRI images -> includes channels and slicing)
import nibabel as nib

To Load ->
image_mri = nib.load('sM00223_002.hdr')
image_mri = image_mri.get_data()
image_mri.shape -> (256, 256, 54, 1)

(256, 256, 54, 1) -> 256,256 -> 54 such images; 1 denotes grey scale images
image_mri = image_mri.squeeze()
image_mri.shape

.squeeze() -> is a NumPy method that removes dimensions of size 1 from an array.
Example usage ->
import numpy as np
arr = np.zeros((1, 4, 1, 5))
print("Before squeeze:", arr.shape)   # (1, 4, 1, 5)
arr_squeezed = arr.squeeze() -> (removes all the 1D's from the data)
print("After squeeze:", arr_squeezed.shape)  # (4, 5)

creating subplots - > to get each image out of the 54 images.
# visualizing images
import matplotlib.pyplot as plt

fig,ax = plt.subplots(nrows=2,ncols=3, figsize=(20,20))

ax[0,0].imshow(image_mri[:, :, 0], cmap = 'gray')
ax[0,1].imshow(image_mri[:, :, 11], cmap = 'gray')
ax[0,2].imshow(image_mri[:, :, 23], cmap = 'gray')
ax[1,0].imshow(image_mri[:, :, 37], cmap = 'gray')
ax[1,1].imshow(image_mri[:, :, 42], cmap = 'gray')
ax[1,2].imshow(image_mri[:, :, 51], cmap = 'gray')

Loading multiple images ->
glob -> 
glob("*.jpg") searches the current working directory for all files ending in .jpg.
It returns a list of filenames (strings).

# reading multiple images
from glob import glob   
image_name = glob("*.jpg")

image_name -> ['car-49278_960_720.jpg', 'beagle-dog.jpg', 'dog.jpg']

image_=[]
for i in image_name:
  image = imread(i)
  imshow(image)
  plt.show()
  image_.append(image)

final_images = np.array(image_) -> displays all the images 
final_images.shape -> (3,) because it has multiple size images and its a 1-d numpy array 

Note -> If all images had the same shape, final_images would become a proper 4D NumPy array. 
But since your images are different sizes, NumPy cannot stack them into one uniform array.
ðŸ‘‰ Instead, it makes a 1D array of objects (each object = one image array)

final_images[0].shape, final_images[1].shape, final_images[2].shape -> ((540, 960, 3), (160, 228, 3), (340, 453, 3))

To resize image we use -> .resize(image,size)  : ex -> resize(final_images[i], (340, 450))
Code ->
final_resized = [] 
for i in range (0,3):
  temp = resize(image[i],(340,450))
  final_resized.append(temp)

resize(final_images[i], (340, 450)) 

final_images.shape -> (3, 340, 450, 3)

the plot to show that ->

# visualizing images
import matplotlib.pyplot as plt
fig,ax = plt.subplots(nrows=1, ncols=2)
ax[0].imshow(final_resized[2])
ax[1].imshow(final_images[2])

Explanation of the plot -> 
fig means the whole canvas , ax is defined my the rows =1 , and cols = 2 ( one row and 2 columns)
ax[0] -> as (1,2) is the shape, ax[0] and ax[1] are 1-d array only we cannot use ax[0,0] or ax[0,1] 



Converting a image from one style to another (rgb -> grayscale , rgba -> rgb)
Important imports -> 

from skimage.color import rgb2gray, rgba2rgb

Initially ->
image_rgba.shape : (340, 453, 4)
image_rgb.shape  : (340, 453, 3)

Code -> 

# converting rgba to rgb
image_rgb = rgba2rgb(image_rgba)
image_rgb.shape 
Output : (340, 453, 3)

# converting rgb to gray
image_gray = rgb2gray(image)
image_gray.shape
Output : (340, 453)

Loading the RGB image in Grayscale format ->
Note: imshow(image_gray) automatically applies a grayscale colormap. ( normally it is false, but if we change it to true this happens :)
image_ = imread('dog.jpg', as_gray=True)
imshow(image_)

Loading the RGBA image in Grayscale format ->
image_ = imread('mid_alpha.png', as_gray=True)
print(image_.shape)
imshow(image_)


Extracting Edges from images ->
What is an Edge in Image Processing?

An edge is a region in an image where the intensity (pixel value) changes sharply.
Edges often represent boundaries of objects, lines, or texture changes.
In other words, edges are locations in the image where the brightness changes abruptly.

Filter or kernel -> is a matrix which helps in comaring the pixel values .
1. Higher the difference ( multiplication with the matrix/kernel) -> pixel is close to edge 
2. Lower the difference ( multiplication with the matrix/kernel)  -> pixel is far from edge / pixel is not at the edge
Filter/kernel ->
-1  0  1
-1  0  1
-1  0  1

| Kernel    | Direction | What it detects  | Axis of change | Intution 
| --------- | --------- | ---------------- | -------------- |
| Prewitt X | X         | Vertical edges   | left â†” right   |Each column compares left pixels vs right pixels in the neighborhood- (changes when moving left â†” right).
| Prewitt Y | Y         | Horizontal edges | top â†” bottom   |Each row compares top pixels vs bottom pixels - (changes when moving top â†” bottom)
| Sobel X   | X         | Vertical edges   | left â†” right   |
| Sobel Y   | Y         | Horizontal edges | top â†” bottom   |


Prewitt x -> 
-1  0  1
-1  0  1
-1  0  1

Prewitt Y ->
-1  -1  -1
 0  0  0
 1  1  1

Sobett x ->
-1  0  1
-2  0  2
-1  0  1

Sobett y >
-1  -2  -1
 0  0  0
 1  2  1


Code ->
#reading the image and plotting it
image = imread('dog.jpg', as_gray=True)
imshow(image,cmap='gray')

Explanation : cmap='gray'
imshow() needs a colormap to map pixel values to colors.
By default, Matplotlib uses a viridis colormap (blue â†’ green â†’ yellow).
Setting cmap='gray' tells Matplotlib to display the 2D array in grayscale.





