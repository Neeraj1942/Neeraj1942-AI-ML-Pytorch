Corpus : A large set of texts
Corpus -> Documents ,tweets, emails -> sentences -> tokens

Tokens : Smaller Units of text (words, characters, n-grams)
N-gram : is a collection of N consecutive tokes (i.e 
Sentence: "I love this town"
Unigrams (n=1): I, love, this, town 
Bigrams (n=2): I love, love this, this town 
Trigrams (n=3): I love this, love this
Note: Observe that the words are repeated in bigram and trigram. ( ALSO THEY CAN BE DEFINED FOR WORDS/CHARECTERS ALSO)

Tokenization ->
1. White Space Tokenizor : Splits the i.e sentences using the white spaces between the words.
2. Smart Tokenizor(spaCy library) : Splits complex nested tokes -> punctuation marks.(i.e "!" ....) -> (i.e Let's -> " Let " , " 's ") 

Text Preprocessing ->
1. Text Cleaning -> Cleaning the text.
Text noise : The unwanted parts of the text. (i.e Unwanted sysbols, Urls tags, html tags)
examples ->
a. URL's, punctuation makrs, numbers
b. Text slangs, non dictionary words, (swag,bro,dope ..etc)
c. Spelling mistakes.(cntrol, plye, finaly...etc)

Fix text encoding and casing-> 
a. ASCII code(english), West Europe(Latin), Big5(Chinese)
b. Universally accepted coding is UTF-8. 
c. Lowercase entire text

Then we remove the noise from the text.

Regular expression or Regex : A tool used for patterns in the text.
Patterns are special charecters with an associated with anassociated textual meaning.(i.e '\d' is used to identify digits, '\w' is used to identify alphanumeric characters)

Next steps in this course are :
1. Important RegEx methods. 
2. RegEx - special sequences.
3. RegEx Metacharecters.
4. RegEx Sets.
5. Practice problems in RegEx.

1. Important RegEx methods :
a. re.match() -> function returns a match object on success and none on failure.(Note : only if the position is also matched, changes to thr string results in 'None' return)

result = re.match('Analytics','Analytics Vidhya is the largest data science community of India') 
print(result)
Output : sunccess object

result_2 = re.match('largest','Analytics Vidhya is the largest data science community of India') 
print(result_2)
Output : None 

Now later to check the get the matched object we do :
print(result.group()) 
output -> Analytics

b. re.search() -> checks if the string1, is present in string2 ( Note : does not care the position and reoccurence of the same)

result = re.search('founded','Andrew NG founded Coursera. He also founded deeplearning.ai')
print(result.group())
output : founded

c. re.findall() -> returns all the occurences in the string. ( i.e if 2 same elements , return them 2 times)

result = re.search('founded','Andrew NG founded Coursera. He also founded deeplearning.ai')
print(result.group())
Output : ['founded', 'founded']

d. re.sub() -> returns the string where matched occurences are replaced with the new string.

result = re.sub('He', 'Andrew NG', 'Andrew NG founded Coursera. He also founded deeplearning.ai')  
print(result)
Ouput : Andrew NG founded Coursera. Andrew NG also founded deeplearning.ai

result = re.sub('also', '', 'Andrew NG founded Coursera. He also founded deeplearning.ai')  
print(result)
Output : Andrew NG founded Coursera. He  founded deeplearning.ai


2. RegEx - special sequences ->

a. '\b' returns a match where the specified pattern is at the beginning or at the end of a word.

# Check if there is any word that ends with "est"
x = re.findall(r"ics\b", "Analytics Vidhya is one of the largest data science communities")
print(x)
Ouput : ['ics']

Note : ics\b , \bics, \bics\b : all these are different. ( \B
x = re.findall(r"ics\b", "Analytics Vidhya is one of Analytics the largest data science communities")
print(x)
Ouput : ['ics','ics']
| Pattern   | Meaning                    | Example Match   |
| --------- | -------------------------- | --------------- |
| `\bcat\b` | “cat” as a whole word      | `"the cat sat"` |
| `\bcat`   | word starting with “cat”   | `"catfish"`     |
| `cat\b`   | word ending with “cat”     | `"wildcat"`     |
| `\Bcat`   | “cat” inside a larger word | `"scatter"`     |


b .  '\d' and '\d+'
1.'\d' returns a match when the string contains digits (numbers from 0-9) :

str = "2 million monthly visits in Jan'19."
# Check if the string contains any digits (numbers from 0-9):
x = re.findall("\d", str)
print(x)
Ouput : ['2', '1', '9']

2. '\d+' returns a match when the string contains digits (numbers from 0-9), till keeps on adding to the string till found a space :

str = "2 million monthly visits in Jan'19."
# Check if the string contains any digits (numbers from 0-9):
# adding '+' after '\d' will continue to extract digits till encounters a space
x = re.findall("\d+", str)
print(x)
Ouput : ['2', '19']

| Pattern | Meaning                           | Example Match in `"Order123"` |
| ------- | --------------------------------- | ----------------------------- |
| `\d`    | Any one digit                     | `"1"`, `"2"`, `"3"`           |
| `\d+`   | One or more digits (whole number) | `"123"`                       |


Note : We can infer that **\d+** repeats one or more occurences of **\d** till the non maching character is found where as **\d** does character wise comparison.

c. '\w' helps in extraction of alphanumeric characters only (characters from a to Z, digits from 0-9, and the underscore _ character) :

str = "2 million monthly visits!"

str = "2 million monthly visits!"
x = re.findall("\w",str)
print(x)
Output : ['2', 'm', 'i', 'l', 'l', 'i', 'o', 'n', 'm', 'o', 'n', 't', 'h', 'l', 'y', 'v', 'i', 's', 'i', 't', 's']

x = re.findall("\w+",str)
print(x)
Ouput : ['2', 'million', 'monthly', 'visits'] 
Note : \w+ -> return the strings till it finds a space

| **Pattern** | **Meaning**                               | **Example**          | **Output**                                              |
| ----------- | ----------------------------------------- | -------------------- | ------------------------------------------------------- |
| `\w`        | Single word character                     | `"Python_3 is fun!"` | `['P','y','t','h','o','n','_','3','i','s','f','u','n']` |
| `\w+`       | One or more word characters               | `"Python_3 is fun!"` | `['Python_3','is','fun']`                               |
| `\W`        | Non-word characters (spaces, punctuation) | `"Python_3 is fun!"` | `[' ', ' ', '!']`                                       |


3. RegEx Metacharecters. -> Metacharacters are characters with a special meaning

a. '(.)' matches any character (except newline character) :

str = "rohan and rohit recently published a research paper!" 
# search for a string that starts with "ro", followed by 1 character
x = re.findall("ro.", str)
print(x)
Ouput : ['roh', 'roh']

# search for a string that starts with "ro", followed by three characters
x2 = re.findall("ro...", str)
print(x2)
Ouput : ['rohan', 'rohit']

| **Pattern** | **Meaning**                                             | **Example** | **Output**             |
| ----------- | ------------------------------------------------------- | ----------- | ---------------------- |
| `.`         | Matches **any single character** except newline `\n`    | `"Py3!"`    | `['P', 'y', '3', '!']` |
| `.+`        | Matches **one or more** of any character (except `\n`)  | `"Py3!"`    | `['Py3!']`             |
| `.*`        | Matches **zero or more** of any character (except `\n`) | `"Py3!"`    | `['Py3!']`             |


b. '(^)' starts with, i.e checks if the string starts with the given substring.
str = "Data Science"
#Check if the string starts with 'Data':
x = re.findall("^Data", str)
if (x):
  print("Yes, the string starts with 'Data'")
else:
  print("No match")
Output : Yes, the string starts with 'Data' 

# try with a different string
str2 = "Big Data"
#Check if the string starts with 'Data':
x2 = re.findall("^Data", str2)
if (x2):
  print("Yes, the string starts with 'data'")
else:
  print("No match")
Output : No match

| Pattern    | Meaning                      | Output       |
| ---------- | ---------------------------- | ------------ |
| `Python^`  | literal `"Python^"`          | `[]`         |
| `^Python^` | line starts with `"Python^"` | `[]`         |
| `^Python`  | line starts with `"Python"`  | `['Python']` |


c. '($)' ends with, i.e if the string ends with the given substring :

str = "Data Science"
#Check if the string ends with 'Science':
x = re.findall("Science$", str)
if (x):
  print("Yes, the string ends with 'Science'")
else:
  print("No match")
Ouput : Yes, the string ends with 'Science

str = "Big Data"
#Check if the string ends with 'Science':
x = re.findall("Science$", str)
if (x):
  print("Yes, the string ends with 'Science'")
else:
  print("No match")
Ouput : No match

| Pattern | Valid? | Meaning                                         | Example Match     |
| ------- | ------ | ----------------------------------------------- | ----------------- |
| `fun$`  | ✅      | “fun” at end of string                          | `"Python is fun"` |
| `$fun`  | ❌      | Invalid — `$` ends string, nothing can follow   | —                 |
| `$fun$` | ❌      | Invalid — `$` can’t appear twice or before text | —                 |


d. (*) matches for zero or more occurences of the pattern to the left of it :

str = "easy easssy eay eaty eay eaay easssssss"
#Check if the string contains "ea" followed by 0 or more "s" characters and ending with y
x = re.findall("eas*y", str)
print(x)
Ouput : ['easy', 'easssy', 'eay']

| **Pattern** | **Meaning**                           | **Example Input** | **Matches**              |
| ----------- | ------------------------------------- | ----------------- | ------------------------ |
| `a*`        | Zero or more `'a'`s                   | `"caaab"`         | `'aaa'`, `' '`           |
| `ab*`       | `'a'` followed by zero or more `'b'`s | `"abb abbb aac"`  | `'abb'`, `'abbb'`, `'a'` |
| `.*`        | Zero or more of **any** character     | `"Python!"`       | `'Python!'`              |


4. RegEx Sets -> A set is a bunch of characters inside a pair of square brackets [ ] with a special meaning.

str = "Analytics Vidhya is one of the largest data science communities"
#Check for the characters y, d, or h, in the above string
x = re.findall("[ydh]", str)
print(x)
Ouput : ['y', 'd', 'h', 'y', 'h', 'd']

str = "Analytics Vidhya is the one of the largest data science communities"
#Check for the characters between a and g, in the above string
x = re.findall("[a-g]", str)
print(x)
Ouput : ['a', 'c', 'd', 'a', 'e', 'e', 'f', 'e', 'a', 'g', 'e', 'd', 'a', 'a', 'c', 'e', 'c', 'e', 'c', 'e']

str = "Analytics Vidhya is one of the largest data sciece communities"
#Check if every word character has characters other than y, d, or h
x = re.findall("[^ydh]", str)
print(x)
Ouput : ['A', 'n', 'a', 'l', 't', 'i', 'c', 's', ' ', 'V', 'i', 'a', ' ', 'i', 's', ' ', 'o', 'n', 'e', ' ', 'o', 'f', ' ', 't', 'e', ' ', 'l', 'a', 'r', 'g', 'e', 's', 't', ' ', 'a', 't', 'a', ' ', 's', 'c', 'i', 'e', 'c', 'e', ' ', 'c', 'o', 'm', 'm', 'u', 'n', 'i', 't', 'i', 'e', 's']

str = "@AnalyticsVidhya"
x = re.findall("[^@]", str)
print(x)
Ouput : ['A', 'n', 'a', 'l', 'y', 't', 'i', 'c', 's', 'V', 'i', 'd', 'h', 'y', 'a']

| **Pattern** | **Meaning**                               | **Example Input** | **Output**                  |
| ----------- | ----------------------------------------- | ----------------- | --------------------------- |
| `[ydh]`     | Matches **y, d, or h**                    | `"Vidhya"`        | `['d', 'h', 'y', 'a']`      |
| `[a-g]`     | Matches **any lowercase letter from a–g** | `"data"`          | `['a', 'd', 'a']`           |
| `[^ydh]`    | Matches **any char except y, d, or h**    | `"Vidhya"`        | `['V', 'i', 'a']`           |
| `[^@]`      | Matches **anything except @**             | `"@Python"`       | `['P','y','t','h','o','n']` |


|  Symbol | Think of it as   | Meaning                                    |
| :-----: | ---------------- | ------------------------------------------ |
|  `[ ]`  | “In the box”     | Match any character *inside* the box       |
|  `[^ ]` | “Not in the box” | Match any character *except* what’s inside |
| `[a-z]` | “Range box”      | Match any character *from a to z*          |


2. Text Representation
We have to convert text to numerical features ->
One hot encoding
Word embeddings

1. One Hot Ecoding ->
a. Text Cleaning
b. Tokenization
c. Vocabulary Preperation
d. One Hot Encoding Vectors

i.e -> lower/upper case , puntuation marks, (after cleaning) -> tokenized -> extract the unique terms
Note : Tokenization, is the most important technique when it comes to one hot encoding. Basically total number of words is important than the corpus

code :
# cleaning
import re

def clean(text):
  #lower case
  text=text.lower()
  
  #remove punctuations
  text=re.sub('[^a-zA-Z]'," ",text)
  
  return text

Ouput ->
['Building some bots for Wikipedia.',
 'Wikipedia is flooded with information.',
 'There is an app for everthing.']

1. first importing 
2. converting all to lower case using , .lower()
3. removing the puntuations, by using , ^ negates the special symbols. and replaces then with "" blank space, sub used to replace the (string1,string2, whole text),[ ] -> helps to capture a word
Now the whole text is cleaned and converted as required.

#call the clean function
cleaned_text=[]

for i in text:
  cleaned_text.append(clean(i))

this creates a loop for ach sentence in the text and return them in a list -> 'building some bots for wikipedia ', 'wikipedia is flooded with information ', 'there is an app for everthing ']

#tokenize the text
tokens=[]

for i in cleaned_text:
  tokens.append(i.split())

print(tokens)

this helps us to print each word as token.-> [['building', 'some', 'bots', 'for', 'wikipedia'], ['wikipedia', 'is', 'flooded', 'with', 'information'], ['there', 'is', 'an', 'app', 'for', 'everthing']]

.split() -> 
'building some bots for wikipedia'.split() -> ['building', 'some', 'bots', 'for', 'wikipedia']

Now removing the duplicates from the corpus ->
#construct vocabulary
vocab=[]

for i in tokens:
  for j in i:
    if j not in vocab:
      vocab.append(j)

#remove duplicate token
vocab = list(set(vocab))

# sort tokens 
vocab.sort()

print(vocab)

vocab = list(set(vocab)) ->
set(vocab) converts the list into a set, which automatically removes duplicates.
list(...) converts it back to a list.

vocab.sort() -> .sort() arranges the words in alphabetical order.

Converting to one hot encoding ->
#one hot vectors
import numpy as np

ohe=np.zeros([len(vocab),len(vocab)])

for i in range(len(ohe)):
  ohe[i][i]=1

ohe = np.zeros([len(vocab), len(vocab)]) -> make a 0's matrix of the size len(vocab) * len(vocab)
for i in range(len(ohe)):
    ohe[i][i] = 1              -> add the 1's in the diagnol elements of the matrix
output :
array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])

a = "this is going to end in 2019 I can't wait for the coming year" 
result = re.sub("\d{4}", "the coming year", a)
result ->"this is going to end in the coming year I can't wait for the coming year"
Explanation :
\d = digit
{4} = exactly 4 of them    (i.e 2019)
You can change the number inside {}:
\d{2} → exactly 2 digits
\d{1,4} → between 1 and 4 digits
\d+ → 1 or more digit

Limitation -> one hot encoding does not understand the sentiment of the data, it just convert everything to unique forms.

Word Embedding :
Vector for a word ( i.e less size also)
Captures the context around the word

Similar words have less angle between them, telling us the context is close for the words
Relationships are preserved

pretrained word embedding ->
1. word2vec
2. GloVe

Code ->
importing the necessary modeule, genism, then loading he KeyedVectors into w2vec object.
from gensim.models import KeyedVectors

# path of the downloaded model
filename = 'GoogleNews-vectors-negative300.bin'

# load into gensim
w2vec = KeyedVectors.load_word2vec_format(filename, binary=True)

wordvec_array = np.zeros((len(vocab), 300)) -> creates a shape of (len)vocab),300
for i, j in enumerate(vocab):
    wordvec_array[i, :] = w2vec.wv.word_vec(j) -> 
enumerate(vocab) gives index i and word j.
w2vec.wv.word_vec(j) (deprecated in gensim ≥4.0) retrieves the 300-dimensional vector for the word j.
wordvec_array[i, :] = ... puts that vector in row i of the array.

The above is the older version ->

The newer model using genism is ->
from gensim.models import KeyedVectors

# path of the downloaded model
filename = 'GoogleNews-vectors-negative300.bin'

# load into gensim
w2vec = KeyedVectors.load_word2vec_format(filename, binary=True)

to check for the word embedding with dimensions (,300)->
# empty array of shape (no. of tokens X 300) to store word2vec features
wordvec_array = np.zeros((len(vocab), 300))

for i,j in enumerate(vocab):
  wordvec_array[i,:] = w2vec[j]

for i,j in enumerate(vocab):
  wordvec_array[i,:] = w2vec[j]
Working ->
vocab = ["king", "queen", "apple"] :
wordvec_array[0, :] → embedding vector for "king"
wordvec_array[1, :] → embedding vector for "queen"
wordvec_array[2, :] → embedding vector for "apple"


