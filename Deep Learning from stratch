Tensor flow playground - https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.53335&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false
In training a neural network, you notice that the loss does not decrease in the few starting epochs ->
| Cause                             | Can prevent early loss drop? |
| --------------------------------- | ---------------------------- |
| I. Learning rate is too low       | ✅ Yes                        |
| II. Regularization parameter high | ✅ Yes                        |
| III. Stuck in local minimum       | ✅ Yes                        |


