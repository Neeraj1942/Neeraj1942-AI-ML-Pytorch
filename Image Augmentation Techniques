Image Augmentation Techniques ->
Instead of collecting more images, we apply transformations to existing images.
The label/class remains the same; only the image appearance changes.

# Image Augmentation Techniques :

1. **Image Rotation**  
   - Rotating the image by a small angle (e.g., ±15°)

2. **Image Shifting (Translation)**  
   - Moving the image along axes:
     - Horizontal shift (left-right)
     - Vertical shift (up-down)

3. **Image Flipping**  
   - Flipping the image along an axis:
     - Left-Right (horizontal flip)  
     - Up-Down (vertical flip)

4. **Image Noising**  
   - Adding random noise to the image to make the model robust (adding small dots on the image)

5. **Image Blurring**  
   - Slightly blurring the image to simulate focus variations or camera shake

1. Image Rotation :
#import required libraries
from skimage.transform import rotate

#rotating the image by 30 degrees
rotated = rotate(image,angle=30)
#plot the rotated image
print('Rotated Image')
imshow(rotated)

2.Image Shifting (Translation) :
After the shift operation, an object present at location (x,y) in the input image is shifted to a new position (X,Y):
**X = x + dx** 
**Y = y + dy** 

#apply shift operation
from skimage.transform import AffineTransform, warp
transform = AffineTransform(translation=(40,40))
Shift = warp(image,transform)

plt.imshow(Shift)
plt.title('Normal Shift')

Now when we specify mode = 'edge' -> this helps to remove the edges from the images(i.e gaps)
wrapShift = warp(image,transform,mode='edge')

3.Image Flipping :
flipLR = np.fliplr(image)  -> numpy module , we use the 'fliplr' function

#flip image left-to-right
flipLR = np.fliplr(image)

#flip image up-to-down
flipLR = np.flipup(image)

#flip image right-to-left
same as np.fliplr(image)
#flip image down-to-up
same as np.flipup(image)

4.Image Noising :
from skimage.util import random_noise

#add random noise to the image
noisyRandom = random_noise(image,var=0.2) -> var means variant specifies the amount of noise you you want to add.

plt.imshow(noisyRandom)
plt.title('Random Noise')

we can also use a predefined distibution (i.e gaussian distribution)
noisyGaussian = random_noise(image,mode='gaussian')

plt.imshow(noisyGaussian)
plt.title('Gaussian Noise')

5.Image Blurring :
#import required libraries
from skimage.filters import gaussian

#blur the image
blurred = gaussian(image,sigma=2.5,multichannel=True)

plt.imshow(blurred)
plt.title('Blurred Image')

sigma → controls the strength of the blur; higher → more blurred.
multichannel → tells the function the image has multiple color channels (RGB); applies blur to each channel separately.

Question : Which line of code correctly specifies shifting an image by 50 pixels horizontally and 40 pixels vertically using AffineTransform?
Sol : AffineTransform(translation=(50,40))


Using the image Emergency vehicle dataset here ,
tqdm -> from tqdm import tqdm : adds an easy progress bar to loops so you can visually track training or processing progress

example usage -> 
from tqdm import tqdm
import time

for i in tqdm(range(100)):
    time.sleep(0.05)

we can also use in data preprocessing where ->
for epoch in tqdm(range(epochs)):
    train_one_epoch()

the ouput looks like : 
100%|████████████████████████████████| 10/10 [00:03<00:00,  3.02it/s]

Understanding the conversion to numpy array ->
X_train = [img0, img1, img2]
y_train = [0, 1, 2]

X_train = np.array(X_train)
y_train = np.array(y_train)

Output :
(3, 224, 224, 3) -> x_train
(3,)             -> y_train


Till now have reshaped the X before, but in this case we have we need the train and validation sets seperate to add more types of augumented images 
so->
we later manually reshape the X_train , and X_validation, later.
Regular : reshape + split  -> X = X.reshape(X.shape[0], 224*224*3) 
This case : split + reshape(X_train) and reshape(X_validation) -> 
1. final_train = final_train.reshape(final_train.shape[0], 224*224*3)
2. final_train = final_train.reshape(final_train.shape[0], 224*224*3)

Regular : X.min(), X.max() ; X.min(), X.max() -> we fund min max and then normalize it.
This case :   # normalizing the pixel values : img = img/255

Note : 1e^-5 = 10^-5

print('Accuracy on validation set:', accuracy_score(y_valid, np.where(model.predict(final_valid)[:, 0]<0.5, 0, 1))) ->
this step is to mark the values to 0 if the value < 0.5 ; otherwise mark it to 1

Instead of using Augmentation for each transformation, we use ->
Image Augmentation using keras (ImageDataGenerator)

from keras.preprocessing.image import ImageDataGenerator -> import Keras’s image augmentation and preprocessing utility.

image_augmentation = ImageDataGenerator(rotation_range=30, width_shift_range=40, height_shift_range=40,
                              horizontal_flip=True, vertical_flip=True, fill_mode="nearest")
Explanation : 
| Parameter               | What it does                                                                          | Example                      |
| ----------------------- | ------------------------------------------------------------------------------------- | ---------------------------- |
| `rotation_range=30`     | Randomly rotates the image up to **±30°**                                             | Tilts the image left/right   |
| `width_shift_range=40`  | Randomly shifts the image **left/right by up to 40 pixels**                           | Moves the image horizontally |
| `height_shift_range=40` | Randomly shifts the image **up/down by up to 40 pixels**                              | Moves the image vertically   |
| `horizontal_flip=True`  | Randomly flips the image horizontally                                                 | Mirror flip (left ↔ right)   |
| `vertical_flip=True`    | Randomly flips the image vertically                                                   | Flip (top ↔ bottom)          |
| `fill_mode="nearest"`   | Fills in new pixels created after shifting/rotating using **nearest neighbor pixels** | Avoids blank areas           |

then we fit the image augmentation to the train data ->
image_augmentation.fit(X_train)

Note: 2 ways to convert the 2-d, 3-d images to 1-d ->
1. model = Sequential()
model.add(InputLayer(input_shape=(224*224*3,)))

2. model=Sequential()
model.add(InputLayer(input_shape=(224,224,3)))
model.add(Flatten())


Note : both serve the same purpose but the way on doing it is different.


Image Generstor and Fit generator :

Note : the image generator function ->
the function is : ImageDataGenerator
image_augmentation = ImageDataGenerator(rotation_range=30, width_shift_range=40, height_shift_range=40,
                              horizontal_flip=True, vertical_flip=True, fill_mode="nearest")

takes a 3 dimensional input only, that is why in in the input layer we use ->
model.add(InputLayer(input_shape=(224,224,3)))
model.add(Flatten())
(keeping the images in the RGB format)

Understanding how we fit the model using image generator function ->
# fits the model on batches with real-time data augmentation:
model_history = model.fit_generator(image_augmentation.flow(X_train, y_train, batch_size=128), validation_data=(X_valid, y_valid), epochs=1)
Explanation : 
model_history = model.fit_generator(...) -> Trains the Keras model on data generated batch by batch, rather than feeding all data at once.
image_augmentation.flow(X_train, y_train, batch_size=128) -> 
image_augmentation -> the object of image generator
flow() method -> Creates a Python generator that outputs batches of augmented images and corresponding labels
batch_size=128 → each batch contains 128 images

model.fit_generator -> train data batch wise
model.fit           -> train data full


Model Checkpointing ->
1. Saves the best model
2. Incase of system failure not everything is lost

Monitor ->
Mode ->
Val_loss(monitor) -> min(mode)
Val_accuracy(monitor) -> max(mode)

Steps to implement the model checkpointing ->
1.Loading the dataset
2.Pre-processing the data
3.Creating training and validation set
4.Defining the model architecture
5.Compiling the model
6.Training the model
Setting up model checkpointing
7.Evaluating model performance

Implementation :
# importing model checkpointing from keras callbacks
from keras.callbacks import ModelCheckpoint

HDF5 stands for Hierarchical Data Format version 5

# defining model checkpointing

# defining the path to store the weights
filepath="best_weights.hdf5"

# defining the model checkpointing and metric to monitor
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

# defining checkpointing variable
callbacks_list = [checkpoint]

model_history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_valid,y_valid), callbacks=callbacks_list)
then using the callable list in the model.fit() function

training the model using early stop ->
model_history  = model.fit(x_train,y_train,epochs = , batch_size = ,validation_data = , callbacks =[early_stopping])

Note : both the early_stopping and checkpoint are called when, the model.fit() as lists, so either you declare them first or later in the module.

checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') ->
ModelCheckpoint()
filepath                -> The path (and filename) where your model weights will be stored.
monitor='val_accuracy'  -> Specifies which metric to track.
verbose=1               -> Controls logging/output during training: 0 → silent, no message; 1 → prints a message whenever the model is saved
save_best_only=True     -> Only saves the model if the monitored metric improves. Saves only the best module
mode='max               -> Tells Keras how to interpret “improvement” for the monitored metric
'max' → higher value is better (use for accuracy, f1_score)
'min' → lower value is better (use for loss)
'auto' → Keras automatically guesses based on the metric name

the functions ->
load_weights() → loads only the learned weights, not the model architecture.
load_model() → loads the full model (architecture + weights + optimizer state).

using the checkpoint ->
model.load_weights("best_weights.hdf5")

This creates a tempory file which can be used in the notebook but does not actually make a file and save it.


